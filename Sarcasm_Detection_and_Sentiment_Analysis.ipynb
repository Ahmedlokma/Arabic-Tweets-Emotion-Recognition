{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "uih2f1ro_vL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3-BS3ZK646N"
      },
      "outputs": [],
      "source": [
        "!pip install numpy gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "qcp7PQf87AZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.org/download/full_grams_cbow_300_twitter/full_grams_cbow_300_twitter.zip\n",
        "!unzip full_grams_cbow_300_twitter.zip"
      ],
      "metadata": {
        "id": "MgOKVZND7ETQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GNvHAFurAvAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyarabic"
      ],
      "metadata": {
        "id": "SVcRdDKLA8VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "79CYi1JOPcP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/ArSarcasm_train.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "PatbvOX_Pf6e",
        "outputId": "92afa182-267f-4964-cd9d-a152da8d433c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  dialect  sarcasm sentiment original_sentiment  \\\n",
              "0    gulf    False  negative           negative   \n",
              "1     msa    False   neutral           positive   \n",
              "2   egypt    False   neutral            neutral   \n",
              "3  levant     True   neutral           negative   \n",
              "4     msa    False   neutral           negative   \n",
              "\n",
              "                                               tweet   source  \n",
              "0  \"Ù†ØµÙŠØ­Ù‡ Ù…Ø§ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ø© Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ Ù…Ø§ ...  semeval  \n",
              "1  \"#Ù†Ø§Ø¯ÙŠÙ†_Ù†Ø³ÙŠØ¨_Ù†Ø¬ÙŠÙ… â¤ï¸â¤ï¸â¤ï¸Ù…Ø¬Ù„Ø© #Ù…Ø§Ø±ÙŠ_ÙƒÙ„ÙŠØ± ğŸ’­#Ù…Ù„ÙƒØ©...  semeval  \n",
              "2                      \"@Alito_NBA Ø§ØªÙˆÙ‚Ø¹ Ø§Ù†Ù‡ Ø¨ÙŠØ³ØªÙ…Ø±\"  semeval  \n",
              "3     \"@KSA24 ÙŠØ¹Ù†ÙŠ \"Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§\" Ù„Ø£Ù† Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ø© Ù…ÙˆØ³ÙƒÙˆ\"  semeval  \n",
              "4  \"RT @alaahmad20: Ù‚Ø§Ø¦Ø¯ ÙÙŠ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„...  semeval  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5cf9c65-4476-40cb-887d-a7c24b63b169\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dialect</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>original_sentiment</th>\n",
              "      <th>tweet</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gulf</td>\n",
              "      <td>False</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>\"Ù†ØµÙŠØ­Ù‡ Ù…Ø§ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ø© Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ Ù…Ø§ ...</td>\n",
              "      <td>semeval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>msa</td>\n",
              "      <td>False</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "      <td>\"#Ù†Ø§Ø¯ÙŠÙ†_Ù†Ø³ÙŠØ¨_Ù†Ø¬ÙŠÙ… â¤ï¸â¤ï¸â¤ï¸Ù…Ø¬Ù„Ø© #Ù…Ø§Ø±ÙŠ_ÙƒÙ„ÙŠØ± ğŸ’­#Ù…Ù„ÙƒØ©...</td>\n",
              "      <td>semeval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>egypt</td>\n",
              "      <td>False</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>\"@Alito_NBA Ø§ØªÙˆÙ‚Ø¹ Ø§Ù†Ù‡ Ø¨ÙŠØ³ØªÙ…Ø±\"</td>\n",
              "      <td>semeval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>levant</td>\n",
              "      <td>True</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "      <td>\"@KSA24 ÙŠØ¹Ù†ÙŠ \"Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§\" Ù„Ø£Ù† Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ø© Ù…ÙˆØ³ÙƒÙˆ\"</td>\n",
              "      <td>semeval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>msa</td>\n",
              "      <td>False</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "      <td>\"RT @alaahmad20: Ù‚Ø§Ø¦Ø¯ ÙÙŠ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„...</td>\n",
              "      <td>semeval</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5cf9c65-4476-40cb-887d-a7c24b63b169')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5cf9c65-4476-40cb-887d-a7c24b63b169 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5cf9c65-4476-40cb-887d-a7c24b63b169');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyJVjf13Pj02",
        "outputId": "4f284b5a-baf7-4e87-8f33-d8e48c76d293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8437 entries, 0 to 8436\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   dialect             8437 non-null   object\n",
            " 1   sarcasm             8437 non-null   bool  \n",
            " 2   sentiment           8437 non-null   object\n",
            " 3   original_sentiment  8437 non-null   object\n",
            " 4   tweet               8437 non-null   object\n",
            " 5   source              8437 non-null   object\n",
            "dtypes: bool(1), object(5)\n",
            "memory usage: 337.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from pyarabic.araby import strip_tashkeel, strip_tatweel"
      ],
      "metadata": {
        "id": "I6etbPfNPzp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline**"
      ],
      "metadata": {
        "id": "dk5Aj2rn7GUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_emojis(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "d8PTsTW6P21N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def tokenize_tweet(tweet):\n",
        " \n",
        "    tokens = nltk.word_tokenize(tweet)\n",
        "  \n",
        "    return tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK9ct63LP8Bd",
        "outputId": "c9c0a7b4-13ae-48c4-8991-ab23acb8ce7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(tokens):\n",
        "    # Remove punctuation from the tokens using a regular expression\n",
        "    no_punct_tokens = [re.sub(r'[^a-zA-ZØ€-Û¿]', '', token) for token in tokens]\n",
        "    \n",
        "    # Remove any empty tokens using a loop\n",
        "    new_tokens = []\n",
        "    for token in no_punct_tokens:\n",
        "        if token:\n",
        "            new_tokens.append(token)\n",
        "    no_punct_tokens = new_tokens\n",
        "    \n",
        "    return no_punct_tokens"
      ],
      "metadata": {
        "id": "NebypG36P_Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(tweet, stopword_file):\n",
        "    with open(stopword_file, 'r', encoding='utf-8') as f:\n",
        "        stop_words = f.read().splitlines()\n",
        "\n",
        "    # Tokenize the tweet\n",
        "    tokens = tweet.split()\n",
        "\n",
        "    no_stopword_tokens = []\n",
        "    for token in tokens:\n",
        "        if token not in stop_words:\n",
        "            no_stopword_tokens.append(token)\n",
        "    \n",
        "    # Join the tokens back into a processed tweet\n",
        "    processed_tweet = \" \".join(no_stopword_tokens)\n",
        "    \n",
        "    return processed_tweet"
      ],
      "metadata": {
        "id": "YKkfcLQLQDTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet2(tweet):\n",
        "    # Remove mentions (@username)\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9_]+\", \"\", tweet)\n",
        "    # Remove retweets (RT)\n",
        "    tweet = re.sub(r\"RT\\s+\", \"\", tweet)\n",
        "    # Remove URLs (http or https)\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", \"\", tweet)\n",
        "    # Remove any remaining non-Arabic characters\n",
        "    tweet = re.sub(r\"[^Ø€-Û¿]+\", \" \", tweet)\n",
        "    # Remove extra whitespace\n",
        "    tweet = re.sub(r\"\\s+\", \" \", tweet.strip())\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "H1rht0_jQG1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(tweet):\n",
        "    tweet = normalize_hamza(tweet)\n",
        "    tweet = strip_tatweel(tweet)\n",
        "    tweet = strip_tashkeel(tweet)\n",
        "\n",
        "\n",
        "    tweet = re.sub(\"[Ù‹ÙŒÙÙÙÙÙ‘Ù’Ù°]\", \"\", tweet)\n",
        "    tweet = re.sub(\"[Ø¥Ø£Ù±Ø¢Ø§]\", \"Ø§\", tweet)\n",
        "    tweet = re.sub(\"Ù‰\", \"ÙŠ\", tweet)\n",
        "    tweet = re.sub(\"Ø¤\", \"Ø¡\", tweet)\n",
        "    tweet = re.sub(\"Ø¦\", \"Ø¡\", tweet)\n",
        "    tweet = re.sub(\"Ø©\", \"Ù‡\", tweet)\n",
        "    noise = re.compile(\"\"\" Ù‘    | # Tashdid\n",
        "                             Ù    | # Fatha\n",
        "                             Ù‹    | # Tanwin Fath\n",
        "                             Ù    | # Damma\n",
        "                             ÙŒ    | # Tanwin Damm\n",
        "                             Ù    | # Kasra\n",
        "                             Ù    | # Tanwin Kasr\n",
        "                             Ù’    | # Sukun\n",
        "                             Ù€     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)\n",
        "    text = re.sub(noise, '', tweet)\n",
        "    tweet = tweet.lower()\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "NZPYb7wMQJPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_hamza(text):\n",
        "    \"\"\"Normalize Alef with Hamza Above and Alef with Hamza Below to Alef\"\"\"\n",
        "    text = re.sub(\"[Ø£Ø¥Ø¢Ø§]\", \"Ø§\", text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "B2qy6vL3QNl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Open the input and output CSV files\n",
        "with open('ArSarcasm_train.csv', 'r', encoding='utf-8') as f_input, \\\n",
        "        open('output_train.csv', 'w', newline='', encoding='utf-8') as f_output:\n",
        "    # Define the CSV reader and writer objects\n",
        "    csv_reader = csv.reader(f_input)\n",
        "    csv_writer = csv.writer(f_output)\n",
        "    \n",
        "    # Read the header row and add a new 'cleaned_tweet' column\n",
        "    header = next(csv_reader)\n",
        "    header.append('cleaned_tweet')\n",
        "    csv_writer.writerow(header)\n",
        "    \n",
        "    # Loop over each row in the input CSV file\n",
        "    for row in csv_reader:\n",
        "        # Get the tweet text from the row\n",
        "         tweet = row[4]\n",
        "        # Clean the tweet text using the cleaning functions\n",
        "         no_stopword_tokens = remove_stopwords(tweet, '/content/list.txt')\n",
        "         tweet = clean_tweet(no_stopword_tokens)\n",
        "         tweet = clean_tweet2(tweet)\n",
        "         tweet = remove_emojis(tweet)\n",
        "         tokens = tokenize_tweet(tweet)\n",
        "         no_punct_tokens = remove_punctuation(tokens)\n",
        "         cleaned_tweet = ' '.join(no_punct_tokens)\n",
        "        \n",
        "        # Add the cleaned tweet text to the row\n",
        "         row.append(cleaned_tweet)\n",
        "        \n",
        "        # Write the updated row to the output CSV file\n",
        "         csv_writer.writerow(row)"
      ],
      "metadata": {
        "id": "w78vIDr8QQyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/output_train.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "TOqjJKYXQgWS",
        "outputId": "4551076d-9b23-4ae9-bf83-93e485994a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  dialect  sarcasm sentiment original_sentiment  \\\n",
              "0    gulf    False  negative           negative   \n",
              "1     msa    False   neutral           positive   \n",
              "2   egypt    False   neutral            neutral   \n",
              "3  levant     True   neutral           negative   \n",
              "4     msa    False   neutral           negative   \n",
              "\n",
              "                                               tweet   source  \\\n",
              "0  \"Ù†ØµÙŠØ­Ù‡ Ù…Ø§ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ø© Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ Ù…Ø§ ...  semeval   \n",
              "1  \"#Ù†Ø§Ø¯ÙŠÙ†_Ù†Ø³ÙŠØ¨_Ù†Ø¬ÙŠÙ… â¤ï¸â¤ï¸â¤ï¸Ù…Ø¬Ù„Ø© #Ù…Ø§Ø±ÙŠ_ÙƒÙ„ÙŠØ± ğŸ’­#Ù…Ù„ÙƒØ©...  semeval   \n",
              "2                      \"@Alito_NBA Ø§ØªÙˆÙ‚Ø¹ Ø§Ù†Ù‡ Ø¨ÙŠØ³ØªÙ…Ø±\"  semeval   \n",
              "3     \"@KSA24 ÙŠØ¹Ù†ÙŠ \"Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§\" Ù„Ø£Ù† Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ø© Ù…ÙˆØ³ÙƒÙˆ\"  semeval   \n",
              "4  \"RT @alaahmad20: Ù‚Ø§Ø¦Ø¯ ÙÙŠ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„...  semeval   \n",
              "\n",
              "                                       cleaned_tweet  \n",
              "0  Ù†ØµÙŠØ­Ù‡ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ù‡ Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ ÙƒÙ†Ø§ Ù…ØªÙˆ...  \n",
              "1        Ù†Ø§Ø¯ÙŠÙ† Ù†Ø³ÙŠØ¨ Ù†Ø¬ÙŠÙ… Ù…Ø¬Ù„Ù‡ Ù…Ø§Ø±ÙŠ ÙƒÙ„ÙŠØ± Ù…Ù„ÙƒÙ‡ Ø§Ù„ØµØ­Ø±Ø§Ø¡  \n",
              "2                                       Ø§ØªÙˆÙ‚Ø¹ Ø¨ÙŠØ³ØªÙ…Ø±  \n",
              "3                    ÙŠØ¹Ù†ÙŠ Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§ Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ù‡ Ù…ÙˆØ³ÙƒÙˆ  \n",
              "4  Ù‚Ø§Ø¡Ø¯ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø³ÙŠØ·Ø±Ù‡ Ø§Ù„Ø§Ù…Ù†ÙŠÙ‡ Ø´Ø±Ù‚ÙŠ Ùˆ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcafb609-ded7-453f-8747-4785fd0e23a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dialect</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>original_sentiment</th>\n",
              "      <th>tweet</th>\n",
              "      <th>source</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gulf</td>\n",
              "      <td>False</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>\"Ù†ØµÙŠØ­Ù‡ Ù…Ø§ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ø© Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ Ù…Ø§ ...</td>\n",
              "      <td>semeval</td>\n",
              "      <td>Ù†ØµÙŠØ­Ù‡ Ø¹Ù…Ø±Ùƒ Ø§ØªÙ†Ø²Ù„ Ù„Ø¹Ø¨Ù‡ Ø³ÙˆØ¨Ø± Ù…Ø§Ø±ÙŠÙˆ Ù…Ø´ Ø²ÙŠ ÙƒÙ†Ø§ Ù…ØªÙˆ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>msa</td>\n",
              "      <td>False</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "      <td>\"#Ù†Ø§Ø¯ÙŠÙ†_Ù†Ø³ÙŠØ¨_Ù†Ø¬ÙŠÙ… â¤ï¸â¤ï¸â¤ï¸Ù…Ø¬Ù„Ø© #Ù…Ø§Ø±ÙŠ_ÙƒÙ„ÙŠØ± ğŸ’­#Ù…Ù„ÙƒØ©...</td>\n",
              "      <td>semeval</td>\n",
              "      <td>Ù†Ø§Ø¯ÙŠÙ† Ù†Ø³ÙŠØ¨ Ù†Ø¬ÙŠÙ… Ù…Ø¬Ù„Ù‡ Ù…Ø§Ø±ÙŠ ÙƒÙ„ÙŠØ± Ù…Ù„ÙƒÙ‡ Ø§Ù„ØµØ­Ø±Ø§Ø¡</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>egypt</td>\n",
              "      <td>False</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>\"@Alito_NBA Ø§ØªÙˆÙ‚Ø¹ Ø§Ù†Ù‡ Ø¨ÙŠØ³ØªÙ…Ø±\"</td>\n",
              "      <td>semeval</td>\n",
              "      <td>Ø§ØªÙˆÙ‚Ø¹ Ø¨ÙŠØ³ØªÙ…Ø±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>levant</td>\n",
              "      <td>True</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "      <td>\"@KSA24 ÙŠØ¹Ù†ÙŠ \"Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§\" Ù„Ø£Ù† Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ø© Ù…ÙˆØ³ÙƒÙˆ\"</td>\n",
              "      <td>semeval</td>\n",
              "      <td>ÙŠØ¹Ù†ÙŠ Ø¨Ù…ÙˆØ§ÙÙ‚ØªÙ†Ø§ Ø¯Ù…Ø´Ù‚ ØµØ§ÙŠØ±Ù‡ Ù…ÙˆØ³ÙƒÙˆ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>msa</td>\n",
              "      <td>False</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "      <td>\"RT @alaahmad20: Ù‚Ø§Ø¦Ø¯ ÙÙŠ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„...</td>\n",
              "      <td>semeval</td>\n",
              "      <td>Ù‚Ø§Ø¡Ø¯ Ø§Ù„Ø­Ø±Ø³ ÙŠØ¹ØªØ±Ù Ø¨ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø³ÙŠØ·Ø±Ù‡ Ø§Ù„Ø§Ù…Ù†ÙŠÙ‡ Ø´Ø±Ù‚ÙŠ Ùˆ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcafb609-ded7-453f-8747-4785fd0e23a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dcafb609-ded7-453f-8747-4785fd0e23a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dcafb609-ded7-453f-8747-4785fd0e23a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWG4H0FmQkUH",
        "outputId": "9682c815-9f73-458e-cbd3-707d1096535b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8437 entries, 0 to 8436\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   dialect             8437 non-null   object\n",
            " 1   sarcasm             8437 non-null   bool  \n",
            " 2   sentiment           8437 non-null   object\n",
            " 3   original_sentiment  8437 non-null   object\n",
            " 4   tweet               8437 non-null   object\n",
            " 5   source              8437 non-null   object\n",
            " 6   cleaned_tweet       8429 non-null   object\n",
            "dtypes: bool(1), object(6)\n",
            "memory usage: 403.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(axis=0,subset= ['dialect','sarcasm','sentiment','original_sentiment','tweet','source','cleaned_tweet'])"
      ],
      "metadata": {
        "id": "SVn2PR18Qmw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxyf_SsuQr5C",
        "outputId": "43e04560-571d-4ac3-980b-7ccbe847f858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 8429 entries, 0 to 8436\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   dialect             8429 non-null   object\n",
            " 1   sarcasm             8429 non-null   bool  \n",
            " 2   sentiment           8429 non-null   object\n",
            " 3   original_sentiment  8429 non-null   object\n",
            " 4   tweet               8429 non-null   object\n",
            " 5   source              8429 non-null   object\n",
            " 6   cleaned_tweet       8429 non-null   object\n",
            "dtypes: bool(1), object(6)\n",
            "memory usage: 469.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('output_train_modified.csv', index=False)  # Save the modified DataFrame to a new CSV file"
      ],
      "metadata": {
        "id": "ntXrx3kvRpJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/output_train_modified.csv\")\n",
        "df.head()\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpek1HlNR5rP",
        "outputId": "09653058-0e4e-4e24-aa9b-ab2c0ecf7108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8429 entries, 0 to 8428\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   dialect             8429 non-null   object\n",
            " 1   sarcasm             8429 non-null   bool  \n",
            " 2   sentiment           8429 non-null   object\n",
            " 3   original_sentiment  8429 non-null   object\n",
            " 4   tweet               8429 non-null   object\n",
            " 5   source              8429 non-null   object\n",
            " 6   cleaned_tweet       8429 non-null   object\n",
            "dtypes: bool(1), object(6)\n",
            "memory usage: 403.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def read_clean_tweets(filename):\n",
        "    \"\"\"\n",
        "    Read a CSV file and extract a column called \"clean_tweet\" into a list.\n",
        "    \n",
        "    Args:\n",
        "    filename - string representing the name of the CSV file\n",
        "    \n",
        "    Returns:\n",
        "    clean_tweets - list of strings representing clean tweets\n",
        "    \"\"\"\n",
        "    clean_tweets = []\n",
        "\n",
        "    with open(filename, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            clean_tweet = row['cleaned_tweet']\n",
        "            clean_tweets.append(clean_tweet)\n",
        "            \n",
        "    return clean_tweets"
      ],
      "metadata": {
        "id": "G5h9mMNBQuwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "\n",
        "def extract_features(data, word_embedding_model):\n",
        "    \"\"\"\n",
        "    Extract TF-IDF features from preprocessed text data using word embeddings.\n",
        "    \n",
        "    Args:\n",
        "    data - list of preprocessed text data\n",
        "    word_embedding_model - pre-trained word embedding model\n",
        "    \n",
        "    Returns:\n",
        "    feature_matrix - sparse matrix of TF-IDF features\n",
        "    \"\"\"\n",
        "    # Get the vocabulary from the word embedding model\n",
        "    vocabulary = set(word_embedding_model.wv.key_to_index.keys())\n",
        "   \n",
        "\n",
        "    # Initialize TfidfVectorizer object with vocabulary\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_df=0.9, min_df=5, ngram_range=(1, 2), vocabulary=vocabulary)\n",
        "\n",
        "    # Fit and transform data to obtain feature matrix\n",
        "    feature_matrix = tfidf_vectorizer.fit_transform(data)\n",
        "\n",
        "    # Save the tfidf_vectorizer for future use\n",
        "    joblib.dump(tfidf_vectorizer, '/content/drive/MyDrive/tfidf_vectorizer_sarcasm2.sav')\n",
        "\n",
        "    return feature_matrix"
      ],
      "metadata": {
        "id": "ZKVsVr3RQ2a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def read_sentiment_labels(filename):\n",
        "    \"\"\"\n",
        "    Read a CSV file and extract a column called \"sentiment\" into a list.\n",
        "    \n",
        "    Args:\n",
        "    filename - string representing the name of the CSV file\n",
        "    \n",
        "    Returns:\n",
        "    sentiment_labels - list of strings representing sentiment labels\n",
        "    \"\"\"\n",
        "    sentiment_labels = []\n",
        "\n",
        "    with open(filename, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            sentiment_label = row['sentiment']\n",
        "            sentiment_labels.append(sentiment_label)\n",
        "\n",
        "    return sentiment_labels"
      ],
      "metadata": {
        "id": "Np_8sZNyQ6eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def read_sarcasm_labels(filename):\n",
        "\n",
        "    sarcasm_labels = []\n",
        "\n",
        "    with open(filename, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            sarcasm_label = row['sarcasm']\n",
        "            sarcasm_labels.append(sarcasm_label)\n",
        "\n",
        "    return sarcasm_labels"
      ],
      "metadata": {
        "id": "ZUPsWMiqQ8ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = joblib.load('/content/drive/MyDrive/tfidf_vectorizer_sarcasm2.sav')\n",
        "xx = read_clean_tweets(\"/content/output_train_modified.csv\")\n",
        "X = tfidf_vectorizer.transform(df['cleaned_tweet'])\n",
        "y = read_sentiment_labels(\"/content/output_train_modified.csv\")\n",
        "z = read_sarcasm_labels(\"/content/output_train_modified.csv\")\n",
        "print(len(z))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COKBNU33RFYc",
        "outputId": "e1ad582e-c2ca-423e-e782-3e3d8b11e985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM (Sarcasm Detection & Sentiment Analysis)**"
      ],
      "metadata": {
        "id": "WG7n0_Qp7kLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import joblib"
      ],
      "metadata": {
        "id": "Q_dTLcj6RJ4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine sentiment and sarcasm labels into a single label\n",
        "combined_labels = [sentiment + '_' + sarcasm for sentiment, sarcasm in zip(y, z)]\n",
        "\n",
        "# Train an SVM model for sentiment and sarcasm analysis\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X, combined_labels)\n",
        "\n",
        "# Evaluate the performance of the SVM model\n",
        "y_pred = svm.predict(X)\n",
        "accuracy = accuracy_score(combined_labels, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(combined_labels, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(svm, '/content/drive/MyDrive/svm_sentiment_sarcasm_model2.sav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McBDsqE0RSet",
        "outputId": "19064d44-9651-4138-a56b-3986bc6fa628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9004626883378811\n",
            "Precision: 0.9021367745873715\n",
            "Recall: 0.9004626883378811\n",
            "F1-score: 0.8927160911999452\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/svm_sentiment_sarcasm_model2.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "\n",
        "# Open the input and output CSV files\n",
        "with open('ArSarcasm_test.csv', 'r', encoding='utf-8') as f_input, \\\n",
        "        open('output_test.csv', 'w', newline='', encoding='utf-8') as f_output:\n",
        "    # Define the CSV reader and writer objects\n",
        "    csv_reader = csv.reader(f_input)\n",
        "    csv_writer = csv.writer(f_output)\n",
        "    \n",
        "    # Read the header row and add a new 'cleaned_tweet' column\n",
        "    header = next(csv_reader)\n",
        "    header.append('cleaned_tweet')\n",
        "    csv_writer.writerow(header)\n",
        "    \n",
        "    # Loop over each row in the input CSV file\n",
        "    for row in csv_reader:\n",
        "        # Get the tweet text from the row\n",
        "         tweet = row[4]\n",
        "        # Clean the tweet text using the cleaning functions\n",
        "         no_stopword_tokens = remove_stopwords(tweet, '/content/list.txt')\n",
        "         tweet = clean_tweet(no_stopword_tokens)\n",
        "         tweet = clean_tweet2(tweet)\n",
        "         tweet = remove_emojis(tweet)\n",
        "         tokens = tokenize_tweet(tweet)\n",
        "         no_punct_tokens = remove_punctuation(tokens)\n",
        "         cleaned_tweet = ' '.join(no_punct_tokens)\n",
        "        \n",
        "        # Add the cleaned tweet text to the row\n",
        "         row.append(cleaned_tweet)\n",
        "        \n",
        "        # Write the updated row to the output CSV file\n",
        "         csv_writer.writerow(row)"
      ],
      "metadata": {
        "id": "yP92D7d1TEA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/output_test.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "1vYO2rrVUCXd",
        "outputId": "51a6b223-6f1f-4366-fc0a-35bdaaad5f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  dialect  sarcasm sentiment original_sentiment  \\\n",
              "0     msa     True  negative           negative   \n",
              "1    gulf    False  positive            neutral   \n",
              "2     msa     True   neutral            neutral   \n",
              "3     msa    False   neutral            neutral   \n",
              "4     msa    False   neutral            neutral   \n",
              "\n",
              "                                               tweet   source  \\\n",
              "0  \"@AbuEmad74241481 @Cesars2014 Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡ ...  semeval   \n",
              "1  \"RT @JannetForster: Ø§Ù„Ø¨Ù†Ø§Øª Ø§Ù„Ù„ÙŠ Ù… ØµØ§Ù…Ùˆ Ø¨Ù‚ÙˆÙ„ÙƒÙ… ...  semeval   \n",
              "2             Ø§Ø´Ø§Ø±Ø© Ø±Ø§Ø¨Ø¹Ø© Ø§Ø´Ø¨Ù‡ Ø¨Ù†Ø§Ø± ØªØ­Ø±Ù‚ Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ÙŠÙŠÙ†     astd   \n",
              "3  \"@EGYPTAIR Ù…Ø§Ù‡ÙŠ Ù…Ù…ÙŠØ²Ø§Øª Ø¯Ø±Ø¬Ù‡ Ø¨Ø²Ù†Ø³ Ø¹Ù„Ù…Ø§Ù‹ Ø§Ù†ÙŠ ÙÙŠ ...  semeval   \n",
              "4  Ù…Ø§ Ù„Ø§ ØªØ±Ø§Ù‡ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ„ÙØ§Ø² Ù…Ù†Ø§ÙØ³Ø© Ø´Ø¯ÙŠØ¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…Ø±Ø´Ø­...  semeval   \n",
              "\n",
              "                                       cleaned_tweet  \n",
              "0  Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡ Ø­Ø·Ù…ÙˆØ§ Ø§Ø³Ø·ÙˆØ±Ù‡ Ø§Ù„Ù…ÙŠØ±ÙƒØ§ÙØ§ Ø§Ù„Ø§Ø³Ø±Ø§Ø¡...  \n",
              "1  Ø§Ù„Ø¨Ù†Ø§Øª Ø§Ù„Ù„ÙŠ ØµØ§Ù…Ùˆ Ø¨Ù‚ÙˆÙ„ÙƒÙ… ØªØ±Ø§ Ø±Ù…Ø¶Ø§Ù† Ù‚Ø±Ø¨ Ù‚Ù„ÙŠÙ„ Ø§Ù„Ù„...  \n",
              "2             Ø§Ø´Ø§Ø±Ù‡ Ø±Ø§Ø¨Ø¹Ù‡ Ø§Ø´Ø¨Ù‡ Ø¨Ù†Ø§Ø± ØªØ­Ø±Ù‚ Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ÙŠÙŠÙ†  \n",
              "3  Ù…Ø§Ù‡ÙŠ Ù…Ù…ÙŠØ²Ø§Øª Ø¯Ø±Ø¬Ù‡ Ø¨Ø²Ù†Ø³ Ø¹Ù„Ù…Ø§ Ø§Ù†ÙŠ Ø¨Ø±ÙˆÙƒØ³ÙŠÙ„ Ø§Ø±ÙŠØ¯ Ø§Ù„...  \n",
              "4  ØªØ±Ø§Ù‡ Ø§Ù„ØªÙ„ÙØ§Ø² Ù…Ù†Ø§ÙØ³Ù‡ Ø´Ø¯ÙŠØ¯Ù‡ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ù‡ÙŠÙ„Ø§Ø±ÙŠ ÙƒÙ„Ù†Øª...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a568875-1057-416d-9454-5328b017ca5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dialect</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>original_sentiment</th>\n",
              "      <th>tweet</th>\n",
              "      <th>source</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>msa</td>\n",
              "      <td>True</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>\"@AbuEmad74241481 @Cesars2014 Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡ ...</td>\n",
              "      <td>semeval</td>\n",
              "      <td>Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡ Ø­Ø·Ù…ÙˆØ§ Ø§Ø³Ø·ÙˆØ±Ù‡ Ø§Ù„Ù…ÙŠØ±ÙƒØ§ÙØ§ Ø§Ù„Ø§Ø³Ø±Ø§Ø¡...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gulf</td>\n",
              "      <td>False</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "      <td>\"RT @JannetForster: Ø§Ù„Ø¨Ù†Ø§Øª Ø§Ù„Ù„ÙŠ Ù… ØµØ§Ù…Ùˆ Ø¨Ù‚ÙˆÙ„ÙƒÙ… ...</td>\n",
              "      <td>semeval</td>\n",
              "      <td>Ø§Ù„Ø¨Ù†Ø§Øª Ø§Ù„Ù„ÙŠ ØµØ§Ù…Ùˆ Ø¨Ù‚ÙˆÙ„ÙƒÙ… ØªØ±Ø§ Ø±Ù…Ø¶Ø§Ù† Ù‚Ø±Ø¨ Ù‚Ù„ÙŠÙ„ Ø§Ù„Ù„...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>msa</td>\n",
              "      <td>True</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Ø§Ø´Ø§Ø±Ø© Ø±Ø§Ø¨Ø¹Ø© Ø§Ø´Ø¨Ù‡ Ø¨Ù†Ø§Ø± ØªØ­Ø±Ù‚ Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ÙŠÙŠÙ†</td>\n",
              "      <td>astd</td>\n",
              "      <td>Ø§Ø´Ø§Ø±Ù‡ Ø±Ø§Ø¨Ø¹Ù‡ Ø§Ø´Ø¨Ù‡ Ø¨Ù†Ø§Ø± ØªØ­Ø±Ù‚ Ø§Ù„Ø§Ù†Ù‚Ù„Ø§Ø¨ÙŠÙŠÙ†</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>msa</td>\n",
              "      <td>False</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>\"@EGYPTAIR Ù…Ø§Ù‡ÙŠ Ù…Ù…ÙŠØ²Ø§Øª Ø¯Ø±Ø¬Ù‡ Ø¨Ø²Ù†Ø³ Ø¹Ù„Ù…Ø§Ù‹ Ø§Ù†ÙŠ ÙÙŠ ...</td>\n",
              "      <td>semeval</td>\n",
              "      <td>Ù…Ø§Ù‡ÙŠ Ù…Ù…ÙŠØ²Ø§Øª Ø¯Ø±Ø¬Ù‡ Ø¨Ø²Ù†Ø³ Ø¹Ù„Ù…Ø§ Ø§Ù†ÙŠ Ø¨Ø±ÙˆÙƒØ³ÙŠÙ„ Ø§Ø±ÙŠØ¯ Ø§Ù„...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>msa</td>\n",
              "      <td>False</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Ù…Ø§ Ù„Ø§ ØªØ±Ø§Ù‡ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ„ÙØ§Ø² Ù…Ù†Ø§ÙØ³Ø© Ø´Ø¯ÙŠØ¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…Ø±Ø´Ø­...</td>\n",
              "      <td>semeval</td>\n",
              "      <td>ØªØ±Ø§Ù‡ Ø§Ù„ØªÙ„ÙØ§Ø² Ù…Ù†Ø§ÙØ³Ù‡ Ø´Ø¯ÙŠØ¯Ù‡ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ù‡ÙŠÙ„Ø§Ø±ÙŠ ÙƒÙ„Ù†Øª...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a568875-1057-416d-9454-5328b017ca5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a568875-1057-416d-9454-5328b017ca5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a568875-1057-416d-9454-5328b017ca5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = joblib.load('/content/drive/MyDrive/tfidf_vectorizer_sarcasm2.sav')"
      ],
      "metadata": {
        "id": "ICxSLOraUIyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx = read_clean_tweets(\"/content/output_test.csv\")\n",
        "tweet_features = tfidf_vectorizer.transform(df['cleaned_tweet'])\n",
        "y = read_sentiment_labels(\"/content/output_test.csv\")\n",
        "z = read_sarcasm_labels(\"/content/output_test.csv\")"
      ],
      "metadata": {
        "id": "l7JRqhouUM95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = joblib.load('/content/drive/MyDrive/svm_sentiment_sarcasm_model2.sav')\n",
        "y_true_combined = [sentiment + '_' + sarcasm for sentiment, sarcasm in zip(y, z)]\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_combined = svm.predict(tweet_features)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(y_true_combined, y_pred_combined)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true_combined, y_pred_combined, average='weighted')\n",
        "report = classification_report(y_true_combined, y_pred_combined)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLD7g6b1UQDW",
        "outputId": "263633d0-5d83-40d6-ead7-d00ef2a728db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5729857819905213\n",
            "Precision: 0.5578532396391767\n",
            "Recall: 0.5729857819905213\n",
            "F1-score: 0.5288367065149547\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "negative_False       0.45      0.31      0.37       417\n",
            " negative_True       0.48      0.25      0.33       299\n",
            " neutral_False       0.60      0.88      0.71      1045\n",
            "  neutral_True       1.00      0.03      0.06        33\n",
            "positive_False       0.60      0.28      0.39       303\n",
            " positive_True       0.00      0.00      0.00        13\n",
            "\n",
            "      accuracy                           0.57      2110\n",
            "     macro avg       0.52      0.29      0.31      2110\n",
            "  weighted avg       0.56      0.57      0.53      2110\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decison Trees (Sarcasm Detection & Sentiment Analysis)**"
      ],
      "metadata": {
        "id": "OjAjNi9l-WT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Combine sentiment and sarcasm labels into a single label\n",
        "combined_labels = [sentiment + '_' + sarcasm for sentiment, sarcasm in zip(y, z)]\n",
        "\n",
        "# Define the decision tree classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "}\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(dt_classifier, param_grid, cv=5)\n",
        "grid_search.fit(X, combined_labels)\n",
        "\n",
        "# Get the best classifier with the optimal hyperparameters\n",
        "dt_best_classifier = grid_search.best_estimator_\n",
        "\n",
        "# Train the decision tree model with the best hyperparameters\n",
        "dt_best_classifier.fit(X, combined_labels)\n",
        "\n",
        "# Evaluate the performance of the decision tree model on the training set\n",
        "y_pred = dt_best_classifier.predict(X)\n",
        "accuracy = accuracy_score(combined_labels, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(combined_labels, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(dt_best_classifier, '/content/drive/MyDrive/dt_sentiment_sarcasm_model.sav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYcmxAFoUUQC",
        "outputId": "bddbbf73-8a69-4118-d8f7-6138cd8e201c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5960374896191719\n",
            "Precision: 0.6164768203632366\n",
            "Recall: 0.5960374896191719\n",
            "F1-score: 0.5427648732843509\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/dt_sentiment_sarcasm_model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt= joblib.load('/content/drive/MyDrive/dt_sentiment_sarcasm_model.sav')\n",
        "y_true_combined = [sentiment + '_' + sarcasm for sentiment, sarcasm in zip(y, z)]\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_combined = dt.predict(tweet_features)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(y_true_combined, y_pred_combined)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true_combined, y_pred_combined, average='weighted')\n",
        "report = classification_report(y_true_combined, y_pred_combined)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD655yShvuKu",
        "outputId": "dbb1c4f6-12fc-4dd1-d0e2-82e4e07f4fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5184834123222749\n",
            "Precision: 0.45723463296121\n",
            "Recall: 0.5184834123222749\n",
            "F1-score: 0.4488373552128162\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "negative_False       0.34      0.15      0.20       417\n",
            " negative_True       0.37      0.22      0.27       299\n",
            " neutral_False       0.56      0.89      0.69      1045\n",
            "  neutral_True       0.00      0.00      0.00        33\n",
            "positive_False       0.42      0.14      0.21       303\n",
            " positive_True       0.00      0.00      0.00        13\n",
            "\n",
            "      accuracy                           0.52      2110\n",
            "     macro avg       0.28      0.23      0.23      2110\n",
            "  weighted avg       0.46      0.52      0.45      2110\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes (Sarcasm Detection & Sentiment Analysis)**"
      ],
      "metadata": {
        "id": "gK7F4Jdr-neZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Combine sentiment and sarcasm labels into a single label\n",
        "combined_labels = [sentiment + '_' + sarcasm for sentiment, sarcasm in zip(y, z)]\n",
        "\n",
        "# Define the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0],  # Smoothing parameter\n",
        "    'fit_prior': [True, False]  # Whether to learn class prior probabilities\n",
        "}\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(nb_classifier, param_grid, cv=5)\n",
        "grid_search.fit(X, combined_labels)\n",
        "\n",
        "# Get the best classifier with the optimal hyperparameters\n",
        "nb_best_classifier = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Train the Naive Bayes model with the best hyperparameters\n",
        "nb_best_classifier.fit(X, combined_labels)\n",
        "\n",
        "# Evaluate the performance of the Naive Bayes model on the training set\n",
        "y_pred = nb_best_classifier.predict(X)\n",
        "accuracy = accuracy_score(combined_labels, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(combined_labels, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(nb_best_classifier, '/content/drive/MyDrive/nb_sentiment_sarcasm_model.sav')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p3HfAgewIhF",
        "outputId": "850c7db9-a55c-4a87-8d69-c97cb9dee642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "{'alpha': 0.1, 'fit_prior': False}\n",
            "Accuracy: 0.9133942341914818\n",
            "Precision: 0.9209953477957414\n",
            "Recall: 0.9133942341914818\n",
            "F1-score: 0.9099460661177752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/nb_sentiment_sarcasm_model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb= joblib.load('/content/drive/MyDrive/nb_sentiment_sarcasm_model.sav')\n",
        "y_true_combined = [sentiment + '_' + sarcasm for sentiment, sarcasm in zip(y, z)]\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_combined = nb.predict(tweet_features)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(y_true_combined, y_pred_combined)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true_combined, y_pred_combined, average='weighted')\n",
        "report = classification_report(y_true_combined, y_pred_combined)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87e-PT6Hwkxj",
        "outputId": "9c70ec74-5ee4-4dba-bffa-c435f04f41ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5630331753554503\n",
            "Precision: 0.5429919151656407\n",
            "Recall: 0.5630331753554503\n",
            "F1-score: 0.5076966158105143\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "negative_False       0.48      0.26      0.33       417\n",
            " negative_True       0.49      0.23      0.31       299\n",
            " neutral_False       0.58      0.91      0.71      1045\n",
            "  neutral_True       0.50      0.03      0.06        33\n",
            "positive_False       0.57      0.22      0.32       303\n",
            " positive_True       0.00      0.00      0.00        13\n",
            "\n",
            "      accuracy                           0.56      2110\n",
            "     macro avg       0.44      0.27      0.29      2110\n",
            "  weighted avg       0.54      0.56      0.51      2110\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing Each Model Individually**"
      ],
      "metadata": {
        "id": "aZeI5pac-7tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ù„ÙŠÙ„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§ÙŠÙÙˆÙ† .. Ø±ØªÙˆÙŠØª Ù„Ù„Ù…Ø±ÙÙ‚Ø© ÙˆØ·Ø¨Ù‚ Ø§Ù„Ø´Ø±ÙˆØ· ğŸ‘‡\"\n",
        "no_stopword_tokens = remove_stopwords(tweet, '/content/list.txt')\n",
        "print(no_stopword_tokens)\n",
        "tweet = clean_tweet(no_stopword_tokens)\n",
        "tweet = clean_tweet2(tweet)\n",
        "tweet = remove_emojis(tweet)\n",
        "tokens = tokenize_tweet(tweet)\n",
        "no_punct_tokens = remove_punctuation(tokens)\n",
        "cleaned_tweet = ' '.join(no_punct_tokens)\n",
        "print(cleaned_tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Cf-O4QHzXPc",
        "outputId": "dedf04e8-a1ee-4559-f837-55389cd3c572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ù„ÙŠÙ„Ø© Ø§Ù„Ø§ÙŠÙÙˆÙ† .. Ø±ØªÙˆÙŠØª Ù„Ù„Ù…Ø±ÙÙ‚Ø© ÙˆØ·Ø¨Ù‚ Ø§Ù„Ø´Ø±ÙˆØ· ğŸ‘‡\n",
            "Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ù„ÙŠÙ„Ù‡ Ø§Ù„Ø§ÙŠÙÙˆÙ† Ø±ØªÙˆÙŠØª Ù„Ù„Ù…Ø±ÙÙ‚Ù‡ ÙˆØ·Ø¨Ù‚ Ø§Ù„Ø´Ø±ÙˆØ·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_features = tfidf_vectorizer.transform([cleaned_tweet])\n",
        "\n",
        "\n",
        "prediction = svm.predict(tweet_features)\n",
        "label_parts = prediction[0].split('_')\n",
        "if label_parts[1] == 'False':\n",
        "    output = 'not-sarcastic'\n",
        "else:\n",
        "    output = 'sarcastic'\n",
        "\n",
        "print(label_parts[0])\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ54wLsCzZGV",
        "outputId": "20acdb49-64fc-43ba-ae5f-d08ffd5f320f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral\n",
            "not-sarcastic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_features = tfidf_vectorizer.transform([cleaned_tweet])\n",
        "\n",
        "\n",
        "prediction = dt.predict(tweet_features)\n",
        "label_parts = prediction[0].split('_')\n",
        "if label_parts[1] == 'False':\n",
        "    output = 'not-sarcastic'\n",
        "else:\n",
        "    output = 'sarcastic'\n",
        "\n",
        "print(label_parts[0])\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHfR-DLTzrVz",
        "outputId": "9cbe6fd4-2269-42b2-9096-e7c7bfd87c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral\n",
            "not-sarcastic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_features = tfidf_vectorizer.transform([cleaned_tweet])\n",
        "\n",
        "\n",
        "prediction = nb.predict(tweet_features)\n",
        "label_parts = prediction[0].split('_')\n",
        "if label_parts[1] == 'False':\n",
        "    output = 'not-sarcastic'\n",
        "else:\n",
        "    output = 'sarcastic'\n",
        "\n",
        "print(label_parts[0])\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie0O1mIPzvgq",
        "outputId": "d16022cc-c709-4605-e885-8d5cdb673cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral\n",
            "not-sarcastic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM (Sarcasm Detection)**"
      ],
      "metadata": {
        "id": "RlQvD4Ab_Mhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import joblib\n",
        "\n",
        "# Train the SVM model on sarcasm data only\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X, z)\n",
        "\n",
        "# Evaluate the performance of the SVM model on sarcasm data\n",
        "y_pred = svm.predict(X)\n",
        "accuracy = accuracy_score(z, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(z, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(svm, '/content/drive/MyDrive/svm_sarcasm_only_model.sav')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kNxH99s0Ccl",
        "outputId": "13e43cf7-78b7-4740-eb75-f585322915d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9422232767825365\n",
            "Precision: 0.9452439939701524\n",
            "Recall: 0.9422232767825365\n",
            "F1-score: 0.9369639241946666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/svm_sarcasm_only_model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import joblib\n",
        "\n",
        "# Load the trained SVM model\n",
        "svm = joblib.load('/content/drive/MyDrive/svm_sarcasm_only_model.sav')\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_sarcasm = svm.predict(tweet_features)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(z, y_pred_sarcasm)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(z, y_pred_sarcasm, average='weighted')\n",
        "report = classification_report(z, y_pred_sarcasm)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPaa6sYf2E4F",
        "outputId": "5ecab254-5a41-4834-b745-4b61fd1f1ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8417061611374408\n",
            "Precision: 0.8063789867498634\n",
            "Recall: 0.8417061611374408\n",
            "F1-score: 0.7940792586072297\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.85      0.98      0.91      1765\n",
            "        True       0.58      0.11      0.19       345\n",
            "\n",
            "    accuracy                           0.84      2110\n",
            "   macro avg       0.72      0.55      0.55      2110\n",
            "weighted avg       0.81      0.84      0.79      2110\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes(Sarcasm Detection)**"
      ],
      "metadata": {
        "id": "p8NmVUsR_dW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import joblib\n",
        "\n",
        "# Define the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0],  # Smoothing parameter\n",
        "    'fit_prior': [True, False]  # Whether to learn class prior probabilities\n",
        "}\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(nb_classifier, param_grid, cv=5)\n",
        "grid_search.fit(X, z)\n",
        "\n",
        "# Get the best classifier with the optimal hyperparameters\n",
        "nb_best_classifier = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Train the Naive Bayes model with the best hyperparameters\n",
        "nb_best_classifier.fit(X, z)\n",
        "\n",
        "# Evaluate the performance of the Naive Bayes model on the training set\n",
        "y_pred = nb_best_classifier.predict(X)\n",
        "accuracy = accuracy_score(z, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(z, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(nb_best_classifier, '/content/drive/MyDrive/nb_sarcasm_only_model.sav')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX13XjOb2hX6",
        "outputId": "cf0e7650-9151-4b2e-edf6-d8d9514f755c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "{'alpha': 0.1, 'fit_prior': False}\n",
            "Accuracy: 0.93830822161585\n",
            "Precision: 0.9423256834274332\n",
            "Recall: 0.93830822161585\n",
            "F1-score: 0.9320014147959964\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/nb_sarcasm_only_model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import joblib\n",
        "\n",
        "# Load the trained Naive Bayes model\n",
        "nb = joblib.load('/content/drive/MyDrive/nb_sarcasm_only_model.sav')\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_sarcasm = nb.predict(tweet_features)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(z, y_pred_sarcasm)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(z, y_pred_sarcasm, average='weighted')\n",
        "report = classification_report(z, y_pred_sarcasm)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eo2YBMw3olN",
        "outputId": "9b8acc66-0548-4ec1-fa90-5850abdb1cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8369668246445497\n",
            "Precision: 0.7909268199157837\n",
            "Recall: 0.8369668246445497\n",
            "F1-score: 0.7847158537981224\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.85      0.98      0.91      1765\n",
            "        True       0.51      0.08      0.14       345\n",
            "\n",
            "    accuracy                           0.84      2110\n",
            "   macro avg       0.68      0.53      0.53      2110\n",
            "weighted avg       0.79      0.84      0.78      2110\n",
            "\n"
          ]
        }
      ]
    }
  ]
}